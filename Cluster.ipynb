{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering on Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statistics import mean,stdev\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_df =pd.read_csv(r\"D:\\Dr. Sheng Li\\Datasets\\UCRArchive_2018\\GunPoint\\sample.tsv\",sep=\"\\t\")# Line 2 in table 2\n",
    "# ts_df.shape\n",
    "# true_labels=ts_df['0']\n",
    "# true_labels=np.array(true_labels)\n",
    "# true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 1: Extracts the uShapelets from the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D: Dataset \n",
    "#### slen: Shapelet lengths(Hyperparameter)\n",
    "#### Returns the uShapelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractUShapelets(D,slen):\n",
    "    ts=D.iloc[0]#copy of first time series in D\n",
    "    shapeletlist=[]#List to store uShapelets\n",
    "    while(True):\n",
    "        sub_list=[] # list of subsequences Line 5 in Table 2\n",
    "        gap=[]\n",
    "        dt=[]\n",
    "        for sl in slen:\n",
    "            count=-1 # count \n",
    "            for j in range(0,(len(ts)-sl)+1):#line 7 in table 2\n",
    "                temp=[]\n",
    "                ts_copy=list(ts[j:(j+sl)])\n",
    "                temp.append(ts_copy)\n",
    "                sub_list.append(temp[0])#Line 8 in table 2\n",
    "                temp_gap,temp_dt=computeGap(sub_list[count+1],D)\n",
    "                gap.append(temp_gap)\n",
    "                dt.append(temp_dt)\n",
    "                count=count+1\n",
    "        index1=gap.index(max(gap))\n",
    "        shapeletlist.append(sub_list[index1])\n",
    "        distance_array=computeDistance(sub_list[index1],D) #Line 12 in table 2\n",
    "\n",
    "        #finding Da-Line 13 in Table 2\n",
    "        Da=[]\n",
    "        for value in distance_array:\n",
    "            if value<dt[index1]:\n",
    "                Da.append(value)\n",
    "        if(len(Da)==1):#Line 14 in Table 2\n",
    "            print(\"uShapelets Identified\")\n",
    "            break\n",
    "        else:\n",
    "            maximum=np.amax(distance_array)\n",
    "            index2=np.where(distance_array==maximum)#Line 16 in Table 2\n",
    "            index2=index2[0][0]\n",
    "            ts=D.iloc[index2]\n",
    "            criteria=np.mean(Da)+np.std(Da)\n",
    "            index_list=[]\n",
    "            for value in distance_array:\n",
    "                if value<criteria:\n",
    "                    index_to_remove=np.where(distance_array==value)\n",
    "                    index_list.append(index_to_remove[0][0])\n",
    "            D=D.drop(D.index[index_list])\n",
    "            D=np.array(D)\n",
    "            D=pd.DataFrame(D)\n",
    "    S=set(tuple(row) for row in shapeletlist)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 2: Computes the maximum gap and dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s: candidate uShapelet\n",
    "#### D: Dataset\n",
    "#### Returns maximum gap score and dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s is the subsequence \n",
    "#D is the Dataset\n",
    "def computeGap(s,D):   \n",
    "    dist=computeDistance(s,D)\n",
    "    sorted_dist=np.sort(dist)#Line 2 in Table 3\n",
    "    maxGap=float(0)\n",
    "    dt=float(0)\n",
    "    k=10#have to change later\n",
    "    for l in range(0,(dist.shape[0]-2)):\n",
    "        d=((sorted_dist[l]+sorted_dist[l+1])/2)\n",
    "        Da,Db=find(d,dist)\n",
    "        r=Da.shape[0]/Db.shape[0]\n",
    "        if r>(1/k) and r<(1-(1/k)):\n",
    "            Ma=mean(Da)\n",
    "            Mb=mean(Db)\n",
    "            sigmaA=np.std(Da)\n",
    "            sigmaB=np.std(Db)\n",
    "            gap=Mb-sigmaB-(Ma+sigmaA)\n",
    "            if gap>maxGap:\n",
    "                maxGap=gap\n",
    "                dt=d\n",
    "#     print(\"MAXGAP\",maxGap)\n",
    "#     print(\"DT\",dt)\n",
    "    return maxGap,dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 3: Computes the Distance between candidate shapelet and dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s: Candidate uShapelet\n",
    "#### D: Dataset\n",
    "#### Returns the distances of all the time series with candidate shapelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s is the subsequence\n",
    "#D is the dataset\n",
    "def computeDistance(s,D):\n",
    "    dis=np.full(D.shape[0],10000)#Line 1 in Table 4\n",
    "    dis=dis.astype('float64')\n",
    "    s_copy=list(s)\n",
    "    s_copy=znorm(s_copy)\n",
    "    for i in range(0,D.shape[0]):\n",
    "        timeseries=D.loc[i]\n",
    "        for j in range(0,(len(timeseries)-len(s)+1)):\n",
    "            timeseries_copy=timeseries[j:(j+len(s))].copy()\n",
    "            z=znorm(timeseries_copy)# Line 6 in Table 4\n",
    "            d=distance.euclidean(z,s_copy)\n",
    "            if float(d)<float(dis[i]):\n",
    "                minimum=float(d)\n",
    "            else:\n",
    "                minimum=float(dis[i])\n",
    "            dis[i]=float(minimum)\n",
    "    return dis/math.sqrt(len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to perform normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ser: Series to perform normalization on\n",
    "#### Returns the normalized series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform z-normalization\n",
    "def znorm(ser):\n",
    "    new_ser=[]\n",
    "    u=mean(ser)\n",
    "    sigma=np.std(ser)\n",
    "    index=0\n",
    "    for value in ser:\n",
    "        new_ser.append((value-u)/sigma)\n",
    "        index=index+1\n",
    "    new_ser=np.array(new_ser)\n",
    "    return new_ser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to find subsets distinguished by a point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d:point\n",
    "#### dis: distance array computed by computeDistance function\n",
    "#### Returns the two subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(d,dis):\n",
    "    DA=[]\n",
    "    DB=[]\n",
    "    for value in range(0,dis.shape[0]):\n",
    "        if dis[value]<d:\n",
    "            DA.append(dis[value])\n",
    "        else:\n",
    "            DB.append(dis[value])\n",
    "    DA=np.array(DA)\n",
    "    DB=np.array(DB)\n",
    "    return DA,DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 4: Implements the kmeans algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D: Dataset\n",
    "#### S: set of ushapelets\n",
    "#### k: number of clusters\n",
    "#### Returns the cluster labels for each time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMEBER TO SEND A NEW COPY OF THE DATASET\n",
    "def clusterData(D,S,k,true_labels):\n",
    "    rowsize=S.shape[0]#number of ushapelets\n",
    "    colsize=D.shape[0]#number of timeseries\n",
    "    inertia=[]#sumd list\n",
    "    DIS=np.zeros(shape=(rowsize,colsize))\n",
    "    label=[]#np.zeros(shape=(colsize,))#cls in paper\n",
    "    kmeans=KMeans(n_clusters=k)\n",
    "    rand_score=[]\n",
    "    for i in range(0,S.shape[0]):\n",
    "        dis=computeDistance(S[i],D)\n",
    "        DIS[i]=dis\n",
    "        sumDIS=float(10000)\n",
    "        DIS_T=DIS.T\n",
    "        for j in range(0,rowsize):\n",
    "            kmeans.fit(DIS_T)\n",
    "            inertia.append(kmeans.inertia_)\n",
    "            if sum(inertia)<sumDIS:\n",
    "                labels_pred=kmeans.labels_\n",
    "                label.append(labels_pred)\n",
    "                score=adjusted_rand_score(true_labels,labels_pred)\n",
    "                rand_score.append(score)\n",
    "    a=rand_score.index(max(rand_score))\n",
    "    return label[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_of_class=max(true_labels)\n",
    "# shape=[3,2]\n",
    "# cluster_list=[]\n",
    "# row_index=[]\n",
    "# for k in range(0,no_of_class):\n",
    "#     D_org=ts_df[ts_df['0']==(k+1)]\n",
    "#     print(D_org)\n",
    "#     row_index=list(D_org.index)\n",
    "#     print(row_index)\n",
    "#     D_org=D_org.reset_index(drop=True)\n",
    "#     labels=D_org['0']\n",
    "#     D_org=D_org.drop(D_org.columns[0],axis=1)\n",
    "#     D=D_org.copy()\n",
    "#     shapelist=extractUShapelets(D,shape)\n",
    "#     S=np.array(list(shapelist))\n",
    "#     D1=D_org.copy()\n",
    "#     cluster=clusterData(D1,S,2,labels)\n",
    "#     cluster_list.append(cluster)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The three functions below identify and return the representatives of various classes of timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_selection(cluster_list,row_indices,ts_df):\n",
    "    indices_list=[]\n",
    "    for lis in cluster_list:\n",
    "        count=5#int((len(cluster_list[0])/4))#HAVE TO CHANGE THIS\n",
    "#         ind=np.where(lis==1)[0]\n",
    "        indices_list.append(representative(lis,count))\n",
    "    return selection(row_indices,ts_df,indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(row_indices,ts_df,indices_list):\n",
    "    rep_ts=[]\n",
    "    counter=0\n",
    "    for i in indices_list:\n",
    "        for j in i:\n",
    "            rep_ts.append(row_indices[counter][j])\n",
    "        counter=counter+1\n",
    "        rep=[]\n",
    "    for i in rep_ts:\n",
    "        temp=list(ts_df.iloc[i])\n",
    "        rep.append(temp)\n",
    "    rep_df=pd.DataFrame(rep)\n",
    "    return rep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative(lis,count):\n",
    "#     ind=np.where(lis==1)[0]\n",
    "# #     count=int((len(cluster_list[0])/4))#HAVE TO CHANGE THIS\n",
    "#     index_list=[]\n",
    "#     counter=0\n",
    "#     temp_list=[]\n",
    "#     while counter<count:\n",
    "#         temp_list.append(ind[counter])\n",
    "#         counter=counter+1\n",
    "#     ind=np.where(lis==0)[0]\n",
    "#     counter=0\n",
    "#     index_list.append(temp_list)\n",
    "#     temp_list=[]\n",
    "#     while counter<count:\n",
    "#         temp_list.append(ind[counter])\n",
    "#         counter=counter+1\n",
    "#     index_list.append(temp_list)\n",
    "    index_list=[0,1]\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function is invoked and drives other functions \n",
    "### returns a dataframe containing the represenatative time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(shape,ts_df,true_labels):\n",
    "    no_of_class=max(true_labels)\n",
    "    cluster_list=[]\n",
    "    row_index=[]\n",
    "    for k in range(0,no_of_class):\n",
    "        D_org=ts_df[ts_df['0']==(k+1)]\n",
    "        row=list(D_org.index)\n",
    "        row_index.append(row)\n",
    "        D_org=D_org.reset_index(drop=True)\n",
    "        labels=D_org['0']\n",
    "        D_org=D_org.drop(D_org.columns[0],axis=1)\n",
    "        D=D_org.copy()\n",
    "        shapelist=extractUShapelets(D,shape)\n",
    "        S=np.array(list(shapelist))\n",
    "        D2=D_org.copy()\n",
    "        cluster=clusterData(D2,S,2,labels)\n",
    "        cluster_list.append(cluster)\n",
    "        print(\"clustering of class\",(k+1),\"complete\")\n",
    "    rep_df=representative_selection(cluster_list,row_index,ts_df)\n",
    "    return rep_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
